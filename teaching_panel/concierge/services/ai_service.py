"""
AIService ‚Äî RAG –∏ LLM –ª–æ–≥–∏–∫–∞

–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
- –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –≤ Knowledge Base
- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LLM
- –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM (DeepSeek/OpenAI)
- –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
"""

import logging
import json
import os
import httpx
from dataclasses import dataclass, field
from typing import List, Optional
from django.conf import settings

logger = logging.getLogger(__name__)


@dataclass
class AIResponse:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç AI"""
    
    decision: str  # 'answer' | 'clarify' | 'action' | 'escalate'
    text: str = ''
    confidence: float = 0.0
    sources: List[dict] = field(default_factory=list)
    model: str = ''
    tokens_used: int = 0
    
    # –î–ª—è action
    action_name: str = ''
    action_params: dict = field(default_factory=dict)
    
    # –î–ª—è escalate
    reason: str = ''


class AIService:
    """
    –°–µ—Ä–≤–∏—Å AI –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π.
    
    Pipeline:
    1. –ü–æ–∏—Å–∫ –≤ Knowledge Base (RAG)
    2. –°–±–æ—Ä–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    3. –ó–∞–ø—Ä–æ—Å –∫ LLM
    4. –ü–∞—Ä—Å–∏–Ω–≥ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    """
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    DEFAULT_PROVIDER = 'deepseek'
    DEEPSEEK_MODEL = 'deepseek-chat'
    OPENAI_MODEL = 'gpt-4o-mini'
    
    TIMEOUT_SECONDS = 30
    MAX_TOKENS = 1000
    TEMPERATURE = 0.3  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    
    @classmethod
    async def process(
        cls,
        conversation,
        message,
        history: list,
    ) -> AIResponse:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            conversation: –û–±—ä–µ–∫—Ç –¥–∏–∞–ª–æ–≥–∞
            message: –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            history: –ü–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Returns:
            AIResponse: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        # 1. –ü–æ–∏—Å–∫ –≤ Knowledge Base
        from .knowledge_service import KnowledgeService
        
        relevant_chunks = await KnowledgeService.search(
            query=message.content,
            language=conversation.language,
            limit=5,
        )
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        from ..models import ActionDefinition
        from asgiref.sync import sync_to_async
        
        available_actions = await sync_to_async(list)(
            ActionDefinition.objects.filter(is_active=True).values(
                'name', 'display_name', 'description', 'trigger_keywords', 'is_read_only'
            )
        )
        
        # 3. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = cls._build_prompt(
            user_message=message.content,
            conversation_context=conversation.user_context,
            page_context={
                'url': conversation.page_url,
                'title': conversation.page_title,
            },
            history=history,
            knowledge_chunks=relevant_chunks,
            available_actions=available_actions,
            language=conversation.language,
            retry_count=conversation.ai_retry_count,
        )
        
        # 4. –ó–∞–ø—Ä–æ—Å –∫ LLM
        try:
            raw_response = await cls._call_llm(prompt, conversation.language)
        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            return AIResponse(
                decision='escalate',
                reason=f"LLM error: {str(e)}",
            )
        
        # 5. –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
        return cls._parse_response(raw_response)
    
    @classmethod
    async def generate_action_response(
        cls,
        conversation,
        action_name: str,
        action_result: dict,
    ) -> AIResponse:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–µ–π—Å—Ç–≤–∏—è.
        
        Args:
            conversation: –û–±—ä–µ–∫—Ç –¥–∏–∞–ª–æ–≥–∞
            action_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
            action_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        
        Returns:
            AIResponse: –û—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        prompt = cls._build_action_response_prompt(
            action_name=action_name,
            action_result=action_result,
            language=conversation.language,
        )
        
        try:
            raw_response = await cls._call_llm(prompt, conversation.language)
            return AIResponse(
                decision='answer',
                text=raw_response.get('text', str(action_result)),
                confidence=0.9,
            )
        except Exception as e:
            # Fallback: –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            logger.warning(f"Failed to generate action response: {e}")
            return AIResponse(
                decision='answer',
                text=action_result.get('message', '–î–µ–π—Å—Ç–≤–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ.'),
                confidence=0.7,
            )
    
    # =========================================================================
    # Private methods
    # =========================================================================
    
    @classmethod
    def _build_prompt(
        cls,
        user_message: str,
        conversation_context: dict,
        page_context: dict,
        history: list,
        knowledge_chunks: list,
        available_actions: list,
        language: str,
        retry_count: int,
    ) -> str:
        """–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM"""
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = cls._get_system_prompt(language)
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_info = f"""
## –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –†–æ–ª—å: {conversation_context.get('role', 'unknown')}
- Email: {conversation_context.get('email', 'unknown')}
- –°—Ç—Ä–∞–Ω–∏—Ü–∞: {page_context.get('title', 'unknown')} ({page_context.get('url', '')})
"""
        
        if 'subscription' in conversation_context:
            sub = conversation_context['subscription']
            user_info += f"- –ü–æ–¥–ø–∏—Å–∫–∞: {sub.get('status', 'unknown')}\n"
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        history_text = "\n## –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞\n"
        for msg in history[-6:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 6 —Å–æ–æ–±—â–µ–Ω–∏–π
            sender = {
                'user': 'üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å',
                'ai': 'ü§ñ AI',
                'admin': 'üë®‚Äçüíº –û–ø–µ—Ä–∞—Ç–æ—Ä',
                'system': '‚öôÔ∏è –°–∏—Å—Ç–µ–º–∞',
            }.get(msg.sender_type, msg.sender_type)
            history_text += f"{sender}: {msg.content[:500]}\n"
        
        # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–Ω–∞–Ω–∏—è (RAG)
        knowledge_text = ""
        if knowledge_chunks:
            knowledge_text = "\n## –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π\n"
            for chunk in knowledge_chunks:
                knowledge_text += f"---\n[{chunk.get('title', 'Doc')}]\n{chunk.get('content', '')}\n"
        
        # –î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        actions_text = "\n## –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è\n"
        if available_actions:
            for action in available_actions:
                actions_text += f"- `{action['name']}`: {action['description'][:100]}\n"
        else:
            actions_text += "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π.\n"
        
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
        instruction = f"""
## –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
{user_message}

## –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤—ã–±–µ—Ä–∏ –û–î–ù–û –¥–µ–π—Å—Ç–≤–∏–µ:

1. **answer** ‚Äî —Ç—ã –º–æ–∂–µ—à—å –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å (–µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏–ª–∏ —ç—Ç–æ –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å)
2. **clarify** ‚Äî –Ω—É–∂–Ω–æ —É—Ç–æ—á–Ω–∏—Ç—å –¥–µ—Ç–∞–ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—É–∂–µ –∑–∞–ø—Ä–æ—à–µ–Ω–æ {retry_count} —Ä–∞–∑, –º–∞–∫—Å–∏–º—É–º 2)
3. **action** ‚Äî –Ω—É–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏–ª–∏ —Ä–µ—à–µ–Ω–∏—è
4. **escalate** ‚Äî –Ω–µ –º–æ–∂–µ—à—å –ø–æ–º–æ—á—å, –Ω—É–∂–µ–Ω —á–µ–ª–æ–≤–µ–∫ (—Å–ª–æ–∂–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞, –ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∂–∞–ª–æ–±–∞)

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
```json
{{
    "decision": "answer|clarify|action|escalate",
    "text": "–¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–∞ {'–∞–Ω–≥–ª–∏–π—Å–∫–æ–º' if language == 'en' else '—Ä—É—Å—Å–∫–æ–º'} —è–∑—ã–∫–µ",
    "confidence": 0.0-1.0,
    "action_name": "–∏–º—è_–¥–µ–π—Å—Ç–≤–∏—è (—Ç–æ–ª—å–∫–æ –¥–ª—è decision=action)",
    "action_params": {{}},
    "reason": "–ø—Ä–∏—á–∏–Ω–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è decision=escalate)"
}}
```

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ retry_count >= 2 –∏ —Ç—ã –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî —ç—Å–∫–∞–ª–∏—Ä—É–π, –Ω–µ –º—É—á–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é ‚Äî –µ—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å, —Å–∫–∞–∂–∏ —á–µ—Å—Ç–Ω–æ
- –î–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º —Å–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–π action (–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞)
- –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É
"""
        
        return f"{system_prompt}\n{user_info}\n{history_text}\n{knowledge_text}\n{actions_text}\n{instruction}"
    
    @classmethod
    def _get_system_prompt(cls, language: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        if language == 'en':
            return """You are Lectio Concierge ‚Äî an AI support assistant for Lectio LMS (Learning Management System).

Your role:
- Help teachers and students with platform usage
- Diagnose technical issues
- Answer questions about features
- Escalate complex issues to human support

Platform features:
- Online lessons with Zoom integration
- Lesson recordings storage
- Homework assignments with auto-grading
- Student groups and schedules
- Subscription payments (YooKassa)

Be friendly, concise, and helpful. If unsure ‚Äî ask clarifying questions or escalate."""
        
        return """–¢—ã ‚Äî Lectio Concierge, AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª—è LMS Lectio (—Å–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏–µ–º).

–¢–≤–æ—è —Ä–æ–ª—å:
- –ü–æ–º–æ–≥–∞—Ç—å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è–º –∏ —Å—Ç—É–¥–µ–Ω—Ç–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
- –î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
- –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ —Ñ—É–Ω–∫—Ü–∏—è—Ö
- –ü–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞–º

–§—É–Ω–∫—Ü–∏–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã:
- –û–Ω–ª–∞–π–Ω-—É—Ä–æ–∫–∏ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Zoom
- –•—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π —É—Ä–æ–∫–æ–≤
- –î–æ–º–∞—à–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è —Å –∞–≤—Ç–æ–ø—Ä–æ–≤–µ—Ä–∫–æ–π
- –ì—Ä—É–ø–ø—ã —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
- –û–ø–ª–∞—Ç–∞ –ø–æ–¥–ø–∏—Å–∫–∏ (YooKassa)

–ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º, –∫—Ä–∞—Ç–∫–∏–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º. –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî –∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–π –æ–ø–µ—Ä–∞—Ç–æ—Ä—É."""
    
    @classmethod
    def _build_action_response_prompt(
        cls,
        action_name: str,
        action_result: dict,
        language: str,
    ) -> str:
        """–ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –¥–µ–π—Å—Ç–≤–∏—è"""
        
        lang_instruction = "in English" if language == 'en' else "–Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ"
        
        return f"""–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è `{action_name}`:

```json
{json.dumps(action_result, ensure_ascii=False, indent=2)}
```

–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {lang_instruction}.
–ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º–∞ ‚Äî –æ–±—ä—è—Å–Ω–∏ –µ—ë –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —Ä–µ—à–µ–Ω–∏–µ.
–ï—Å–ª–∏ –≤—Å—ë –≤ –ø–æ—Ä—è–¥–∫–µ ‚Äî –ø–æ–¥—Ç–≤–µ—Ä–¥–∏ —ç—Ç–æ.

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
```json
{{
    "text": "–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"
}}
```"""
    
    @classmethod
    async def _call_llm(cls, prompt: str, language: str) -> dict:
        """–í—ã–∑–≤–∞—Ç—å LLM API"""
        provider = os.getenv('CONCIERGE_AI_PROVIDER', cls.DEFAULT_PROVIDER)
        
        if provider == 'deepseek':
            return await cls._call_deepseek(prompt)
        elif provider == 'openai':
            return await cls._call_openai(prompt)
        else:
            raise ValueError(f"Unknown AI provider: {provider}")
    
    @classmethod
    async def _call_deepseek(cls, prompt: str) -> dict:
        """–í—ã–∑–≤–∞—Ç—å DeepSeek API"""
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if not api_key:
            raise ValueError("DEEPSEEK_API_KEY not configured")
        
        async with httpx.AsyncClient(timeout=cls.TIMEOUT_SECONDS) as client:
            response = await client.post(
                'https://api.deepseek.com/chat/completions',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json',
                },
                json={
                    'model': cls.DEEPSEEK_MODEL,
                    'messages': [
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': cls.MAX_TOKENS,
                    'temperature': cls.TEMPERATURE,
                    'response_format': {'type': 'json_object'},
                },
            )
            response.raise_for_status()
            data = response.json()
            
            content = data['choices'][0]['message']['content']
            return json.loads(content)
    
    @classmethod
    async def _call_openai(cls, prompt: str) -> dict:
        """–í—ã–∑–≤–∞—Ç—å OpenAI API"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY not configured")
        
        async with httpx.AsyncClient(timeout=cls.TIMEOUT_SECONDS) as client:
            response = await client.post(
                'https://api.openai.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json',
                },
                json={
                    'model': cls.OPENAI_MODEL,
                    'messages': [
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': cls.MAX_TOKENS,
                    'temperature': cls.TEMPERATURE,
                    'response_format': {'type': 'json_object'},
                },
            )
            response.raise_for_status()
            data = response.json()
            
            content = data['choices'][0]['message']['content']
            return json.loads(content)
    
    @classmethod
    def _parse_response(cls, raw: dict) -> AIResponse:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç LLM –≤ AIResponse"""
        try:
            return AIResponse(
                decision=raw.get('decision', 'escalate'),
                text=raw.get('text', ''),
                confidence=float(raw.get('confidence', 0.5)),
                action_name=raw.get('action_name', ''),
                action_params=raw.get('action_params', {}),
                reason=raw.get('reason', ''),
            )
        except Exception as e:
            logger.error(f"Failed to parse AI response: {e}, raw: {raw}")
            return AIResponse(
                decision='escalate',
                reason=f"Failed to parse AI response: {e}",
            )
